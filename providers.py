"""
æ‰€æœ‰æ¨¡å‹æä¾›å•†å®ç°
æ”¯æŒ OpenAIã€Anthropicã€Alibaba ç­‰å¤šä¸ªæœåŠ¡å•†
"""

import os
from abc import ABC, abstractmethod
from dataclasses import dataclass, field
from typing import List, Dict, Any, Optional, Type
from enum import Enum
from openai import AsyncOpenAI
from anthropic import AsyncAnthropic


# ============================================
# åŸºç¡€ç±»å‹å®šä¹‰
# ============================================

class ModelCapability(str, Enum):
    """æ¨¡å‹èƒ½åŠ›æšä¸¾"""
    REASONING = "reasoning"
    CODING = "coding"
    CREATIVITY = "creativity"
    MATH = "math"
    MULTILINGUAL = "multilingual"
    LONG_CONTEXT = "long_context"
    FAST_RESPONSE = "fast_response"
    VISION = "vision"
    FUNCTION_CALLING = "function_calling"


class PerformanceLevel(str, Enum):
    """æ€§èƒ½çº§åˆ«"""
    OUTSTANDING = "outstanding"
    EXCELLENT = "excellent"
    GOOD = "good"
    MEDIUM = "medium"
    BASIC = "basic"


@dataclass
class ModelInfo:
    """æ¨¡å‹ä¿¡æ¯"""
    model_id: str
    display_name: str
    provider: str
    capabilities: List[ModelCapability] = field(default_factory=list)
    strengths: List[str] = field(default_factory=list)
    suitable_tasks: List[str] = field(default_factory=list)
    performance_profile: Dict[str, PerformanceLevel] = field(default_factory=dict)
    context_window: int = 128000
    max_output_tokens: int = 4096
    supports_streaming: bool = True
    cost_tier: str = "medium"
    speed_tier: str = "medium"
    is_available: bool = True
    version: Optional[str] = None
    special_features: List[str] = field(default_factory=list)

    def __post_init__(self):
        if not self.performance_profile:
            self.performance_profile = {
                "reasoning": PerformanceLevel.MEDIUM,
                "creativity": PerformanceLevel.MEDIUM,
                "coding": PerformanceLevel.MEDIUM,
                "factual": PerformanceLevel.MEDIUM,
            }


# ============================================
# Provider æŠ½è±¡åŸºç±»
# ============================================

class BaseProvider(ABC):
    """åŸºç¡€æ¨¡å‹æä¾›å•†æŠ½è±¡ç±»"""

    def __init__(self, api_key: Optional[str] = None, base_url: Optional[str] = None, **kwargs):
        self.api_key = api_key
        self.base_url = base_url
        self.config = kwargs
        self._models_cache: Optional[List[ModelInfo]] = None

    @property
    @abstractmethod
    def provider_name(self) -> str:
        """æä¾›å•†åç§°"""
        pass

    @abstractmethod
    async def discover_models(self) -> List[ModelInfo]:
        """å‘ç°å¹¶è¿”å›è¯¥æä¾›å•†æ”¯æŒçš„æ‰€æœ‰æ¨¡å‹"""
        pass

    @abstractmethod
    async def call_model(
        self,
        model_id: str,
        messages: List[Dict[str, str]],
        temperature: float = 0.7,
        max_tokens: Optional[int] = None,
        **kwargs
    ) -> str:
        """è°ƒç”¨æ¨¡å‹ç”Ÿæˆå›ç­”"""
        pass

    @abstractmethod
    def is_available(self) -> bool:
        """æ£€æŸ¥æä¾›å•†æ˜¯å¦å¯ç”¨"""
        pass

    async def get_models(self, force_refresh: bool = False) -> List[ModelInfo]:
        """è·å–æ¨¡å‹åˆ—è¡¨ï¼ˆå¸¦ç¼“å­˜ï¼‰"""
        if self._models_cache is None or force_refresh:
            self._models_cache = await self.discover_models()
        return self._models_cache

    def validate_config(self) -> Dict[str, Any]:
        """éªŒè¯é…ç½®"""
        return {
            "valid": self.is_available(),
            "provider": self.provider_name,
            "has_api_key": bool(self.api_key),
            "base_url": self.base_url
        }


# ============================================
# Universal Provider (OpenAI å…¼å®¹)
# ============================================

class UniversalProvider(BaseProvider):
    """
    é€šç”¨ OpenAI å…¼å®¹ API æä¾›å•†
    æ”¯æŒä»»ä½•å®ç°äº† OpenAI Chat Completions API çš„æœåŠ¡
    """

    # é»˜è®¤æ¨¡å‹çŸ¥è¯†åº“
    DEFAULT_MODELS_KNOWLEDGE = {
        "qwen-max": {
            "display_name": "é€šä¹‰åƒé—® Max",
            "capabilities": [ModelCapability.REASONING, ModelCapability.MULTILINGUAL, ModelCapability.LONG_CONTEXT],
            "strengths": ["ä¸­æ–‡ç†è§£é¡¶å°–", "çŸ¥è¯†è¦†ç›–å¹¿", "å¤šè¯­è¨€æ”¯æŒå¼º"],
            "suitable_tasks": ["ä¸­æ–‡å†…å®¹å¤„ç†", "å¤šè¯­è¨€ç¿»è¯‘", "çŸ¥è¯†é—®ç­”"],
            "performance_profile": {
                "reasoning": PerformanceLevel.EXCELLENT,
                "creativity": PerformanceLevel.GOOD,
                "coding": PerformanceLevel.GOOD,
                "factual": PerformanceLevel.EXCELLENT,
            },
            "context_window": 32000,
            "cost_tier": "medium",
            "speed_tier": "medium"
        },
        "qwen-plus": {
            "display_name": "é€šä¹‰åƒé—® Plus",
            "capabilities": [ModelCapability.MULTILINGUAL, ModelCapability.FAST_RESPONSE],
            "strengths": ["ä¸­æ–‡å¤„ç†ä¼˜ç§€", "å¹³è¡¡æ€§èƒ½å¥½", "æ€§ä»·æ¯”é«˜"],
            "suitable_tasks": ["ä¸­æ–‡é—®ç­”", "é€šç”¨ä»»åŠ¡", "ä¿¡æ¯å¤„ç†"],
            "performance_profile": {
                "reasoning": PerformanceLevel.GOOD,
                "creativity": PerformanceLevel.GOOD,
                "coding": PerformanceLevel.GOOD,
                "factual": PerformanceLevel.GOOD,
            },
            "context_window": 32000,
            "cost_tier": "low",
            "speed_tier": "fast"
        },
        "claude_sonnet4": {
            "display_name": "Claude Sonnet 4",
            "capabilities": [ModelCapability.REASONING, ModelCapability.CODING, ModelCapability.CREATIVITY],
            "strengths": ["é€»è¾‘æ¨ç†å“è¶Š", "ä»£ç èƒ½åŠ›é¡¶å°–", "åˆ›æ„å†™ä½œä¼˜ç§€"],
            "suitable_tasks": ["å¤æ‚ç¼–ç¨‹", "æŠ€æœ¯å†™ä½œ", "æ·±åº¦åˆ†æ"],
            "performance_profile": {
                "reasoning": PerformanceLevel.EXCELLENT,
                "creativity": PerformanceLevel.EXCELLENT,
                "coding": PerformanceLevel.EXCELLENT,
                "factual": PerformanceLevel.GOOD,
            },
            "context_window": 200000,
            "cost_tier": "high",
            "speed_tier": "medium"
        },
        "gpt-41-0414-global": {
            "display_name": "GPT-4.1",
            "capabilities": [ModelCapability.REASONING, ModelCapability.CODING, ModelCapability.MATH],
            "strengths": ["æ•°å­¦å’Œç§‘å­¦è®¡ç®—å¼º", "é€»è¾‘æ¨ç†ä¸¥è°¨", "ä»£ç ä¼˜åŒ–èƒ½åŠ›"],
            "suitable_tasks": ["æ•°å­¦é—®é¢˜", "ç§‘å­¦è®¡ç®—", "ç®—æ³•è®¾è®¡"],
            "performance_profile": {
                "reasoning": PerformanceLevel.EXCELLENT,
                "creativity": PerformanceLevel.GOOD,
                "coding": PerformanceLevel.EXCELLENT,
                "factual": PerformanceLevel.EXCELLENT,
            },
            "context_window": 128000,
            "cost_tier": "high",
            "speed_tier": "medium"
        },
        "claude37_sonnet_new": {
            "display_name": "Claude 3.7 Sonnet",
            "capabilities": [ModelCapability.REASONING, ModelCapability.FAST_RESPONSE],
            "strengths": ["å¹³è¡¡çš„ç»¼åˆèƒ½åŠ›", "å¿«é€Ÿå“åº”", "ç¨³å®šæ€§å¥½"],
            "suitable_tasks": ["æ—¥å¸¸é—®ç­”", "ä¿¡æ¯æ€»ç»“", "é€šç”¨ä»»åŠ¡"],
            "performance_profile": {
                "reasoning": PerformanceLevel.GOOD,
                "creativity": PerformanceLevel.GOOD,
                "coding": PerformanceLevel.GOOD,
                "factual": PerformanceLevel.GOOD,
            },
            "context_window": 200000,
            "cost_tier": "medium",
            "speed_tier": "fast"
        },
        "gpt-41-mini-0414-global": {
            "display_name": "GPT-4.1 Mini",
            "capabilities": [ModelCapability.FAST_RESPONSE],
            "strengths": ["æé€Ÿå“åº”", "è½»é‡çº§ä»»åŠ¡", "æ€§ä»·æ¯”é«˜"],
            "suitable_tasks": ["å¿«é€Ÿé—®ç­”", "ç®€å•ç¼–ç¨‹", "æ‰¹é‡å¤„ç†"],
            "performance_profile": {
                "reasoning": PerformanceLevel.MEDIUM,
                "creativity": PerformanceLevel.MEDIUM,
                "coding": PerformanceLevel.GOOD,
                "factual": PerformanceLevel.GOOD,
            },
            "context_window": 128000,
            "cost_tier": "low",
            "speed_tier": "very_fast"
        },
        "glm-4.5": {
            "display_name": "æ™ºè°± GLM-4.5",
            "capabilities": [ModelCapability.REASONING, ModelCapability.MULTILINGUAL],
            "strengths": ["å¤šæ¨¡æ€èƒ½åŠ›", "ä¸­æ–‡ä¼˜åŒ–", "ç»¼åˆåˆ†æèƒ½åŠ›"],
            "suitable_tasks": ["å¤šæ¨¡æ€ä»»åŠ¡", "åˆ›æ–°è®¾è®¡", "ç»¼åˆåˆ†æ"],
            "performance_profile": {
                "reasoning": PerformanceLevel.GOOD,
                "creativity": PerformanceLevel.EXCELLENT,
                "coding": PerformanceLevel.GOOD,
                "factual": PerformanceLevel.GOOD,
            },
            "context_window": 128000,
            "cost_tier": "medium",
            "speed_tier": "medium"
        },
        "qwen3-coder-480b-a35b-instruct": {
            "display_name": "Qwen3 Coder 480B",
            "capabilities": [ModelCapability.CODING],
            "strengths": ["ä»£ç ç”Ÿæˆé¡¶å°–", "ç®—æ³•ç†è§£æ·±", "å¤šè¯­è¨€ç¼–ç¨‹"],
            "suitable_tasks": ["ä»£ç ç”Ÿæˆ", "ç®—æ³•å®ç°", "ä»£ç å®¡æŸ¥"],
            "performance_profile": {
                "reasoning": PerformanceLevel.EXCELLENT,
                "creativity": PerformanceLevel.GOOD,
                "coding": PerformanceLevel.OUTSTANDING,
                "factual": PerformanceLevel.EXCELLENT,
            },
            "context_window": 32000,
            "cost_tier": "high",
            "speed_tier": "medium",
            "special_features": ["480Bè¶…å¤§è§„æ¨¡", "ä»£ç ä¸“ç²¾"]
        },
    }

    def __init__(self, api_key: Optional[str] = None, base_url: Optional[str] = None, **kwargs):
        super().__init__(api_key=api_key, base_url=base_url or "https://api.openai.com/v1", **kwargs)
        self.client = None
        if self.is_available():
            self.client = AsyncOpenAI(api_key=self.api_key, base_url=self.base_url)
        self.custom_models_list = kwargs.get("models_list", None)

    @property
    def provider_name(self) -> str:
        return "universal"

    def is_available(self) -> bool:
        return bool(self.api_key)

    async def discover_models(self) -> List[ModelInfo]:
        if not self.is_available():
            return []

        models = []

        # è·å–æ¨¡å‹åˆ—è¡¨
        if self.custom_models_list:
            model_ids = self.custom_models_list
        elif os.getenv("AVAILABLE_MODELS"):
            model_ids = [m.strip() for m in os.getenv("AVAILABLE_MODELS").split(",")]
        else:
            model_ids = list(self.DEFAULT_MODELS_KNOWLEDGE.keys())

        # åˆ›å»º ModelInfo
        for model_id in model_ids:
            if model_id in self.DEFAULT_MODELS_KNOWLEDGE:
                info = self.DEFAULT_MODELS_KNOWLEDGE[model_id]
                models.append(ModelInfo(model_id=model_id, provider=self.provider_name, **info))
            else:
                # æœªçŸ¥æ¨¡å‹ä½¿ç”¨é»˜è®¤é…ç½®
                models.append(ModelInfo(
                    model_id=model_id,
                    display_name=model_id,
                    provider=self.provider_name,
                    capabilities=[ModelCapability.REASONING],
                    strengths=["é€šç”¨AIèƒ½åŠ›"],
                    suitable_tasks=["é€šç”¨ä»»åŠ¡"]
                ))

        return models

    async def call_model(
        self,
        model_id: str,
        messages: List[Dict[str, str]],
        temperature: float = 0.7,
        max_tokens: Optional[int] = None,
        **kwargs
    ) -> str:
        if not self.client:
            raise ValueError(f"{self.provider_name} provider is not available")

        response = await self.client.chat.completions.create(
            model=model_id,
            messages=messages,
            temperature=temperature,
            max_tokens=max_tokens or 2000,
            **kwargs
        )
        return response.choices[0].message.content


# ============================================
# Anthropic Provider
# ============================================

class AnthropicProvider(BaseProvider):
    """Anthropic Claude API æä¾›å•†"""

    def __init__(self, api_key: Optional[str] = None, base_url: Optional[str] = None, **kwargs):
        super().__init__(api_key=api_key, base_url=base_url, **kwargs)
        self.client = None
        if self.is_available():
            self.client = AsyncAnthropic(api_key=self.api_key)

    @property
    def provider_name(self) -> str:
        return "anthropic"

    def is_available(self) -> bool:
        return bool(self.api_key)

    async def discover_models(self) -> List[ModelInfo]:
        if not self.is_available():
            return []

        return [
            ModelInfo(
                model_id="claude-3-5-sonnet-20241022",
                display_name="Claude 3.5 Sonnet",
                provider=self.provider_name,
                capabilities=[ModelCapability.REASONING, ModelCapability.CODING, ModelCapability.CREATIVITY, ModelCapability.LONG_CONTEXT],
                strengths=["å“è¶Šçš„é€»è¾‘æ¨ç†", "é¡¶çº§ä»£ç èƒ½åŠ›", "åˆ›æ„å†™ä½œä¼˜ç§€", "é•¿æ–‡æœ¬ç†è§£"],
                suitable_tasks=["å¤æ‚ç¼–ç¨‹", "æŠ€æœ¯å†™ä½œ", "åˆ›æ„å†…å®¹", "æ·±åº¦åˆ†æ"],
                performance_profile={
                    "reasoning": PerformanceLevel.EXCELLENT,
                    "creativity": PerformanceLevel.EXCELLENT,
                    "coding": PerformanceLevel.EXCELLENT,
                    "factual": PerformanceLevel.GOOD,
                },
                context_window=200000,
                max_output_tokens=8192,
                cost_tier="high",
                speed_tier="medium",
                special_features=["200Kä¸Šä¸‹æ–‡", "å¼ºé€»è¾‘æ¨ç†"]
            ),
            ModelInfo(
                model_id="claude-3-haiku-20240307",
                display_name="Claude 3 Haiku",
                provider=self.provider_name,
                capabilities=[ModelCapability.FAST_RESPONSE, ModelCapability.CODING],
                strengths=["æé€Ÿå“åº”", "é«˜æ•ˆå¤„ç†", "æ€§ä»·æ¯”ä¼˜ç§€"],
                suitable_tasks=["å¿«é€Ÿé—®ç­”", "ç®€å•ç¼–ç¨‹", "æ–‡æœ¬å¤„ç†"],
                performance_profile={
                    "reasoning": PerformanceLevel.GOOD,
                    "creativity": PerformanceLevel.GOOD,
                    "coding": PerformanceLevel.GOOD,
                    "factual": PerformanceLevel.GOOD,
                },
                context_window=200000,
                max_output_tokens=4096,
                cost_tier="low",
                speed_tier="very_fast"
            ),
        ]

    async def call_model(
        self,
        model_id: str,
        messages: List[Dict[str, str]],
        temperature: float = 0.7,
        max_tokens: Optional[int] = None,
        **kwargs
    ) -> str:
        if not self.client:
            raise ValueError(f"{self.provider_name} provider is not available")

        # Anthropic éœ€è¦å°†ç³»ç»Ÿæ¶ˆæ¯å•ç‹¬å¤„ç†
        system_message = None
        chat_messages = []

        for msg in messages:
            if msg.get("role") == "system":
                system_message = msg.get("content")
            else:
                chat_messages.append(msg)

        response = await self.client.messages.create(
            model=model_id,
            messages=chat_messages if chat_messages else messages,
            system=system_message,
            temperature=temperature,
            max_tokens=max_tokens or 4096,
            **kwargs
        )
        return response.content[0].text


# ============================================
# Model Registry
# ============================================

@dataclass
class ProviderConfig:
    """æä¾›å•†é…ç½®"""
    provider_class: Type[BaseProvider]
    api_key_env: str
    base_url_env: Optional[str] = None
    enabled: bool = True
    custom_config: Dict[str, Any] = None

    def __post_init__(self):
        if self.custom_config is None:
            self.custom_config = {}


class ModelRegistry:
    """
    æ¨¡å‹æ³¨å†Œä¸­å¿ƒ
    è´Ÿè´£ç®¡ç†æ‰€æœ‰æä¾›å•†å’Œæ¨¡å‹
    """

    # é»˜è®¤æä¾›å•†é…ç½®
    DEFAULT_PROVIDERS = {
        "universal": ProviderConfig(
            provider_class=UniversalProvider,
            api_key_env="OPENAI_API_KEY",
            base_url_env="OPENAI_BASE_URL"
        ),
        "anthropic": ProviderConfig(
            provider_class=AnthropicProvider,
            api_key_env="ANTHROPIC_API_KEY"
        ),
    }

    def __init__(self, custom_providers: Optional[Dict[str, ProviderConfig]] = None):
        self.providers: Dict[str, BaseProvider] = {}
        self._all_models: List[ModelInfo] = []
        self._models_by_provider: Dict[str, List[ModelInfo]] = {}

        # åˆå¹¶é…ç½®
        provider_configs = {**self.DEFAULT_PROVIDERS}
        if custom_providers:
            provider_configs.update(custom_providers)

        # åˆå§‹åŒ–æä¾›å•†
        for name, config in provider_configs.items():
            if not config.enabled:
                continue

            api_key = os.getenv(config.api_key_env)
            base_url = os.getenv(config.base_url_env) if config.base_url_env else None

            provider = config.provider_class(api_key=api_key, base_url=base_url, **config.custom_config)

            if provider.is_available():
                self.providers[name] = provider
                print(f"âœ… å·²åŠ è½½æä¾›å•†: {provider.provider_name}")
            else:
                print(f"âš ï¸ æä¾›å•† {name} ä¸å¯ç”¨ï¼ˆæœªé…ç½® API Keyï¼‰")

    async def discover_all_models(self, force_refresh: bool = False) -> List[ModelInfo]:
        """å‘ç°æ‰€æœ‰å¯ç”¨æ¨¡å‹"""
        if self._all_models and not force_refresh:
            return self._all_models

        self._all_models = []
        self._models_by_provider = {}

        for provider_name, provider in self.providers.items():
            try:
                models = await provider.get_models(force_refresh=force_refresh)
                self._all_models.extend(models)
                self._models_by_provider[provider_name] = models
                print(f"ğŸ“¦ {provider_name}: å‘ç° {len(models)} ä¸ªæ¨¡å‹")
            except Exception as e:
                print(f"âŒ å‘ç° {provider_name} æ¨¡å‹å¤±è´¥: {e}")

        return self._all_models

    def get_model(self, model_id: str) -> Optional[ModelInfo]:
        """æ ¹æ®æ¨¡å‹IDè·å–æ¨¡å‹ä¿¡æ¯"""
        for model in self._all_models:
            if model.model_id == model_id:
                return model
        return None

    async def call_model(
        self,
        model_id: str,
        messages: List[Dict[str, str]],
        **kwargs
    ) -> str:
        """è°ƒç”¨æŒ‡å®šæ¨¡å‹"""
        model_info = self.get_model(model_id)
        if not model_info:
            raise ValueError(f"æœªæ‰¾åˆ°æ¨¡å‹: {model_id}")

        provider = self.providers.get(model_info.provider)
        if not provider:
            raise ValueError(f"æä¾›å•† {model_info.provider} ä¸å¯ç”¨")

        return await provider.call_model(model_id, messages, **kwargs)

    def list_available_providers(self) -> List[str]:
        """åˆ—å‡ºæ‰€æœ‰å¯ç”¨çš„æä¾›å•†"""
        return list(self.providers.keys())
