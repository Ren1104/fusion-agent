"""
AI Fusion æ™ºèƒ½æ¨¡å‹é€‰æ‹©å™¨
ä½¿ç”¨LLMåˆ†æé—®é¢˜å¹¶æ¨èæœ€é€‚åˆçš„æ¨¡å‹ç»„åˆ
"""

import json
import re
from typing import List, Dict, Any, Optional
from dataclasses import dataclass
from ai_fusion.utils.helpers import call_llm_async, ModelConfig


@dataclass
class ModelCapability:
    """æ¨¡å‹èƒ½åŠ›æè¿°"""
    name: str
    provider: str
    strengths: List[str]
    suitable_tasks: List[str]
    performance_profile: Dict[str, str]
    special_features: List[str]


class AIFusionSmartSelector:
    """AI Fusionæ™ºèƒ½æ¨¡å‹é€‰æ‹©å™¨"""
    
    def __init__(self):
        self.analyzer_model = "claude_sonnet4"  # ç”¨äºåˆ†æçš„æ¨¡å‹
        self.model_knowledge = self._build_model_knowledge()
    
    def _build_model_knowledge(self) -> Dict[str, ModelCapability]:
        """æ„å»ºæ¨¡å‹çŸ¥è¯†åº“ - åŒ…å«æ‰€æœ‰å¯ç”¨æ¨¡å‹çš„è¯¦ç»†èƒ½åŠ›æè¿°"""
        return {
            # ============= Claude ç³»åˆ— =============
            "claude_sonnet4": ModelCapability(
                name="claude_sonnet4",
                provider="anthropic",
                strengths=[
                    "é€»è¾‘æ¨ç†èƒ½åŠ›å“è¶Š", "ä»£ç ç†è§£å’Œç”Ÿæˆé¡¶å°–", "å¤æ‚é—®é¢˜æ·±åº¦åˆ†æ",
                    "åˆ›æ„å†™ä½œä¼˜ç§€", "å¤šæ­¥éª¤ä»»åŠ¡å¤„ç†", "ç»“æ„åŒ–è¾“å‡ºç²¾å‡†",
                    "é•¿æ–‡æœ¬ç†è§£", "ç»†è‡´çš„ä¸Šä¸‹æ–‡æŠŠæ¡"
                ],
                suitable_tasks=[
                    "ç¼–ç¨‹å’ŒæŠ€æœ¯é—®é¢˜", "é€»è¾‘æ¨ç†", "åˆ›æ„å†™ä½œ", "å¤æ‚åˆ†æ",
                    "å­¦æœ¯ç ”ç©¶", "äº§å“è®¾è®¡", "ç­–ç•¥è§„åˆ’", "ä»£ç å®¡æŸ¥",
                    "ç³»ç»Ÿæ¶æ„è®¾è®¡", "æŠ€æœ¯æ–‡æ¡£ç¼–å†™"
                ],
                performance_profile={
                    "reasoning": "excellent",      # æ¨ç†èƒ½åŠ›ï¼šå“è¶Š
                    "creativity": "excellent",     # åˆ›é€ åŠ›ï¼šå“è¶Š
                    "coding": "excellent",         # ç¼–ç¨‹èƒ½åŠ›ï¼šå“è¶Š
                    "factual": "good",             # äº‹å®å‡†ç¡®æ€§ï¼šè‰¯å¥½
                    "speed": "medium",             # å“åº”é€Ÿåº¦ï¼šä¸­ç­‰
                    "context": "excellent"         # ä¸Šä¸‹æ–‡ç†è§£ï¼šå“è¶Š
                },
                special_features=["æ”¯æŒ200K+é•¿æ–‡æœ¬", "å¼ºé€»è¾‘æ¨ç†é“¾", "åˆ›æ„æ€§å¼º", "é“å¾·å®‰å…¨æ„è¯†é«˜"]
            ),

            "claude37_sonnet_new": ModelCapability(
                name="claude37_sonnet_new",
                provider="anthropic",
                strengths=[
                    "å¹³è¡¡çš„ç»¼åˆèƒ½åŠ›", "å¿«é€Ÿå“åº”", "æ—¥å¸¸å¯¹è¯æµç•…",
                    "ä¿¡æ¯æ•´ç†æ¸…æ™°", "ä¸­ç­‰å¤æ‚åº¦ä»»åŠ¡", "ç¨³å®šæ€§å¥½"
                ],
                suitable_tasks=[
                    "æ—¥å¸¸é—®ç­”", "ä¿¡æ¯æ€»ç»“", "ç¿»è¯‘", "ç®€å•åˆ†æ",
                    "æ–‡æ¡£æ•´ç†", "åŸºç¡€ç¼–ç¨‹", "é€šç”¨ä»»åŠ¡", "å®¢æœå¯¹è¯",
                    "å†…å®¹æ¶¦è‰²", "å¿«é€ŸåŸå‹å¼€å‘"
                ],
                performance_profile={
                    "reasoning": "good",
                    "creativity": "good",
                    "coding": "good",
                    "factual": "good",
                    "speed": "fast",
                    "context": "good"
                },
                special_features=["å“åº”å¿«é€Ÿ", "ç¨³å®šå¯é ", "å¹³è¡¡å‘å±•", "æˆæœ¬æ•ˆç›Šå¥½"]
            ),

            # ============= GPT ç³»åˆ— =============
            "gpt-41-0414-global": ModelCapability(
                name="gpt-41-0414-global",
                provider="openai",
                strengths=[
                    "æ•°å­¦å’Œç§‘å­¦è®¡ç®—å¼º", "é€»è¾‘æ¨ç†ä¸¥è°¨", "ç»“æ„åŒ–åˆ†æç²¾ç¡®",
                    "ä»£ç ä¼˜åŒ–èƒ½åŠ›", "æŠ€æœ¯æ–‡æ¡£å¤„ç†", "å¤šè¯­è¨€æ”¯æŒ",
                    "å·¥å…·è°ƒç”¨èƒ½åŠ›", "å‡½æ•°è°ƒç”¨ç²¾å‡†"
                ],
                suitable_tasks=[
                    "æ•°å­¦é—®é¢˜", "ç§‘å­¦è®¡ç®—", "ç®—æ³•è®¾è®¡", "æ•°æ®åˆ†æ",
                    "æŠ€æœ¯æ–‡æ¡£", "ç³»ç»Ÿè®¾è®¡", "å·¥ç¨‹é—®é¢˜", "APIå¼€å‘",
                    "æ•°æ®å¯è§†åŒ–", "ç»Ÿè®¡åˆ†æ"
                ],
                performance_profile={
                    "reasoning": "excellent",
                    "creativity": "good",
                    "coding": "excellent",
                    "factual": "excellent",
                    "speed": "medium",
                    "context": "excellent"
                },
                special_features=["æ•°å­¦èƒ½åŠ›å¼º", "é€»è¾‘ä¸¥è°¨", "æŠ€æœ¯å¯¼å‘", "128Kä¸Šä¸‹æ–‡", "å·¥å…·ä½¿ç”¨"]
            ),

            "gpt-41-mini-0414-global": ModelCapability(
                name="gpt-41-mini-0414-global",
                provider="openai",
                strengths=[
                    "æé€Ÿå“åº”", "è½»é‡çº§ä»»åŠ¡", "æ—¥å¸¸å¯¹è¯",
                    "ç®€å•é—®ç­”é«˜æ•ˆ", "æˆæœ¬ä¼˜åŒ–", "æ‰¹é‡å¤„ç†é€‚åˆ"
                ],
                suitable_tasks=[
                    "å¿«é€Ÿé—®ç­”", "ç®€å•ç¿»è¯‘", "åŸºç¡€å¯¹è¯", "ä¿¡æ¯æŸ¥æ‰¾",
                    "è½»é‡çº§ç¼–ç¨‹", "æ ¼å¼è½¬æ¢", "æ•ˆç‡ä»»åŠ¡", "æ‰¹é‡å¤„ç†",
                    "å®æ—¶å¯¹è¯", "å¿«é€ŸåŸå‹"
                ],
                performance_profile={
                    "reasoning": "medium",
                    "creativity": "medium",
                    "coding": "good",
                    "factual": "good",
                    "speed": "very_fast",
                    "context": "good"
                },
                special_features=["æé€Ÿå“åº”", "èµ„æºèŠ‚çº¦", "ç®€æ´é«˜æ•ˆ", "æ€§ä»·æ¯”æé«˜"]
            ),

            "gpt-5-mini-0807-global": ModelCapability(
                name="gpt-5-mini-0807-global",
                provider="openai",
                strengths=[
                    "æ–°ä¸€ä»£è½»é‡æ¨¡å‹", "é€Ÿåº¦ä¸è´¨é‡å¹³è¡¡", "æ”¹è¿›çš„æ¨ç†èƒ½åŠ›",
                    "æ›´å¥½çš„æŒ‡ä»¤éµå¾ª", "å¤šä»»åŠ¡å¤„ç†", "æˆæœ¬æ•ˆç›Šä¼˜"
                ],
                suitable_tasks=[
                    "é€šç”¨é—®ç­”", "æ–‡æœ¬ç”Ÿæˆ", "ç®€å•ç¼–ç¨‹", "ä¿¡æ¯æå–",
                    "å¯¹è¯ç³»ç»Ÿ", "å†…å®¹å®¡æ ¸", "åˆ†ç±»ä»»åŠ¡", "æ‘˜è¦ç”Ÿæˆ",
                    "æƒ…æ„Ÿåˆ†æ", "å®ä½“è¯†åˆ«"
                ],
                performance_profile={
                    "reasoning": "good",
                    "creativity": "good",
                    "coding": "good",
                    "factual": "good",
                    "speed": "very_fast",
                    "context": "good"
                },
                special_features=["GPT-5ç³»åˆ—", "é€Ÿåº¦å¿«", "è´¨é‡æå‡", "æŒ‡ä»¤éµå¾ªå¥½"]
            ),

            # ============= é€šä¹‰åƒé—®ç³»åˆ— =============
            "qwen-max": ModelCapability(
                name="qwen-max",
                provider="alibaba",
                strengths=[
                    "ä¸­æ–‡ç†è§£é¡¶å°–", "çŸ¥è¯†è¦†ç›–å¹¿", "å¤šè¯­è¨€æ”¯æŒå¼º",
                    "æ–‡åŒ–è¯­å¢ƒç†è§£æ·±", "æœ¬åœŸåŒ–å†…å®¹ç²¾å‡†", "æ¨ç†èƒ½åŠ›å¼º",
                    "é•¿æ–‡æœ¬å¤„ç†", "ä¸“ä¸šé¢†åŸŸçŸ¥è¯†"
                ],
                suitable_tasks=[
                    "ä¸­æ–‡å†…å®¹å¤„ç†", "ç¿»è¯‘ä»»åŠ¡", "æ–‡åŒ–ç›¸å…³é—®é¢˜",
                    "æœ¬åœŸåŒ–å†…å®¹", "å¤šè¯­è¨€å¯¹è¯", "çŸ¥è¯†é—®ç­”",
                    "ä¸“ä¸šæ–‡æ¡£", "å­¦æœ¯ç ”ç©¶", "å•†ä¸šåˆ†æ"
                ],
                performance_profile={
                    "reasoning": "excellent",
                    "creativity": "good",
                    "coding": "good",
                    "factual": "excellent",
                    "speed": "medium",
                    "context": "excellent"
                },
                special_features=["ä¸­æ–‡ä¼˜åŒ–", "çŸ¥è¯†ä¸°å¯Œ", "æ–‡åŒ–ç†è§£", "32Kä¸Šä¸‹æ–‡"]
            ),

            "qwen-plus": ModelCapability(
                name="qwen-plus",
                provider="alibaba",
                strengths=[
                    "ä¸­æ–‡å¤„ç†ä¼˜ç§€", "å¹³è¡¡æ€§èƒ½å¥½", "å¤šé¢†åŸŸçŸ¥è¯†",
                    "å®ç”¨æ€§å¼º", "æ€§ä»·æ¯”é«˜", "å“åº”ç¨³å®š"
                ],
                suitable_tasks=[
                    "ä¸­æ–‡é—®ç­”", "é€šç”¨ä»»åŠ¡", "çŸ¥è¯†æ•´ç†",
                    "å®ç”¨å·¥å…·", "æ—¥å¸¸åŠ©æ‰‹", "ä¿¡æ¯å¤„ç†",
                    "å†…å®¹ç”Ÿæˆ", "æ–‡æœ¬åˆ†æ"
                ],
                performance_profile={
                    "reasoning": "good",
                    "creativity": "good",
                    "coding": "good",
                    "factual": "good",
                    "speed": "fast",
                    "context": "good"
                },
                special_features=["ä¸­æ–‡å‹å¥½", "å®ç”¨å¯¼å‘", "æ€§ä»·æ¯”é«˜", "ç¨³å®šå¯é "]
            ),

            "qwen3-max-preview": ModelCapability(
                name="qwen3-max-preview",
                provider="alibaba",
                strengths=[
                    "ç¬¬ä¸‰ä»£æ¶æ„", "æ¨ç†èƒ½åŠ›å¢å¼º", "å¤šæ¨¡æ€ç†è§£",
                    "ä»£ç èƒ½åŠ›æå‡", "çŸ¥è¯†æ›´æ–°", "é•¿æ–‡æœ¬ä¼˜åŒ–"
                ],
                suitable_tasks=[
                    "å¤æ‚æ¨ç†", "ä»£ç ç”Ÿæˆ", "å¤šæ¨¡æ€åˆ†æ",
                    "é•¿æ–‡æ¡£å¤„ç†", "ä¸“ä¸šé—®ç­”", "åˆ›æ–°è®¾è®¡",
                    "æŠ€æœ¯ç ”ç©¶", "æ•°æ®åˆ†æ"
                ],
                performance_profile={
                    "reasoning": "excellent",
                    "creativity": "excellent",
                    "coding": "excellent",
                    "factual": "excellent",
                    "speed": "medium",
                    "context": "excellent"
                },
                special_features=["Qwen3æ¶æ„", "å¤šæ¨¡æ€", "é•¿æ–‡æœ¬", "æœ€æ–°æŠ€æœ¯"]
            ),

            # ============= æ™ºè°±AIç³»åˆ— =============
            "glm-4.5": ModelCapability(
                name="glm-4.5",
                provider="zhipu",
                strengths=[
                    "å¤šæ¨¡æ€èƒ½åŠ›å¼º", "è§†è§‰ç†è§£å¥½", "ç»¼åˆåˆ†æèƒ½åŠ›",
                    "åˆ›æ–°æ€§æ€ç»´", "ä¸­æ–‡ä¼˜åŒ–", "è·¨åª’ä½“å¤„ç†"
                ],
                suitable_tasks=[
                    "å¤šæ¨¡æ€ä»»åŠ¡", "åˆ›æ–°è®¾è®¡", "ç»¼åˆåˆ†æ",
                    "å›¾æ–‡ç†è§£", "è·¨é¢†åŸŸé—®é¢˜", "åˆ›æ„é¡¹ç›®",
                    "è§†è§‰é—®ç­”", "å†…å®¹åˆ›ä½œ"
                ],
                performance_profile={
                    "reasoning": "good",
                    "creativity": "excellent",
                    "coding": "good",
                    "factual": "good",
                    "speed": "medium",
                    "context": "good"
                },
                special_features=["å¤šæ¨¡æ€", "åˆ›æ–°æ€ç»´", "ç»¼åˆèƒ½åŠ›", "ä¸­æ–‡ä¼˜ç§€"]
            ),

            # ============= Qwen3-Coderç³»åˆ— (ä»£ç ä¸“ç²¾) =============
            "qwen3-coder-480b-a35b-instruct": ModelCapability(
                name="qwen3-coder-480b-a35b-instruct",
                provider="alibaba",
                strengths=[
                    "ä»£ç ç”Ÿæˆé¡¶å°–", "ç®—æ³•ç†è§£æ·±", "å¤šè¯­è¨€ç¼–ç¨‹",
                    "ä»£ç è¡¥å…¨ç²¾å‡†", "bugä¿®å¤èƒ½åŠ›", "æ¶æ„è®¾è®¡",
                    "480Bå‚æ•°è§„æ¨¡", "æŒ‡ä»¤éµå¾ªå¥½"
                ],
                suitable_tasks=[
                    "ä»£ç ç”Ÿæˆ", "ç®—æ³•å®ç°", "ä»£ç å®¡æŸ¥", "bugä¿®å¤",
                    "é‡æ„ä¼˜åŒ–", "æŠ€æœ¯æ–‡æ¡£", "APIè®¾è®¡", "æµ‹è¯•ç¼–å†™",
                    "æ€§èƒ½ä¼˜åŒ–", "æ¶æ„è®¾è®¡"
                ],
                performance_profile={
                    "reasoning": "excellent",
                    "creativity": "good",
                    "coding": "outstanding",     # ç¼–ç¨‹èƒ½åŠ›ï¼šæ°å‡º
                    "factual": "excellent",
                    "speed": "medium",
                    "context": "excellent"
                },
                special_features=["480Bè¶…å¤§è§„æ¨¡", "ä»£ç ä¸“ç²¾", "å¤šè¯­è¨€", "æŒ‡ä»¤éµå¾ª"]
            ),

            "qwen3-coder-plus1": ModelCapability(
                name="qwen3-coder-plus1",
                provider="alibaba",
                strengths=[
                    "ä»£ç ç”Ÿæˆä¼˜ç§€", "ç¼–ç¨‹æ•ˆç‡é«˜", "å¤šè¯­è¨€æ”¯æŒ",
                    "å¿«é€Ÿå¼€å‘", "å®ç”¨å¯¼å‘", "æ€§ä»·æ¯”å¥½"
                ],
                suitable_tasks=[
                    "å¿«é€Ÿå¼€å‘", "ä»£ç è¡¥å…¨", "ç®€å•é‡æ„", "è„šæœ¬ç¼–å†™",
                    "å·¥å…·å¼€å‘", "è‡ªåŠ¨åŒ–ä»»åŠ¡", "åŸå‹å¼€å‘", "ä»£ç è½¬æ¢"
                ],
                performance_profile={
                    "reasoning": "good",
                    "creativity": "medium",
                    "coding": "excellent",
                    "factual": "good",
                    "speed": "fast",
                    "context": "good"
                },
                special_features=["ä»£ç ä¼˜åŒ–", "å¿«é€Ÿå“åº”", "å®ç”¨æ€§å¼º", "æ€§ä»·æ¯”é«˜"]
            ),

            "qwen3-coder-plus": ModelCapability(
                name="qwen3-coder-plus",
                provider="alibaba",
                strengths=[
                    "ä»£ç èƒ½åŠ›å¼º", "å¹³è¡¡æ€§èƒ½", "å¤šåœºæ™¯é€‚ç”¨",
                    "å¼€å‘æ•ˆç‡", "ç¨³å®šå¯é "
                ],
                suitable_tasks=[
                    "é€šç”¨ç¼–ç¨‹", "ä»£ç ç”Ÿæˆ", "æŠ€æœ¯é—®ç­”", "å¼€å‘è¾…åŠ©",
                    "ä»£ç è§£é‡Š", "å­¦ä¹ è¾…å¯¼", "ä»£ç ä¼˜åŒ–"
                ],
                performance_profile={
                    "reasoning": "good",
                    "creativity": "medium",
                    "coding": "excellent",
                    "factual": "good",
                    "speed": "fast",
                    "context": "good"
                },
                special_features=["ä»£ç èƒ½åŠ›", "å¹³è¡¡å‘å±•", "ç¨³å®šæ€§å¥½", "å®ç”¨"]
            ),

            # ============= OpenMatrixç³»åˆ— (å¼€æºç”Ÿæ€) =============
            "openmatrix-qwen3-235b-inst-fp8": ModelCapability(
                name="openmatrix-qwen3-235b-inst-fp8",
                provider="openmatrix",
                strengths=[
                    "è¶…å¤§è§„æ¨¡235B", "æŒ‡ä»¤éµå¾ªç²¾å‡†", "FP8ä¼˜åŒ–",
                    "æ¨ç†æ•ˆç‡é«˜", "çŸ¥è¯†å¹¿åš", "å¤šä»»åŠ¡èƒ½åŠ›"
                ],
                suitable_tasks=[
                    "å¤æ‚æ¨ç†", "ä¸“ä¸šé—®ç­”", "æ·±åº¦åˆ†æ", "çŸ¥è¯†æ•´åˆ",
                    "å¤šæ­¥éª¤ä»»åŠ¡", "ç³»ç»Ÿè®¾è®¡", "ç ”ç©¶è¾…åŠ©", "åˆ›æ–°æ€è€ƒ"
                ],
                performance_profile={
                    "reasoning": "excellent",
                    "creativity": "good",
                    "coding": "good",
                    "factual": "excellent",
                    "speed": "medium",
                    "context": "excellent"
                },
                special_features=["235Bè§„æ¨¡", "FP8é‡åŒ–", "å¼€æºç”Ÿæ€", "é«˜æ•ˆæ¨ç†"]
            )
        }
    
    async def intelligent_model_selection(
        self, 
        question: str, 
        available_models: List[ModelConfig]
    ) -> Dict[str, Any]:
        """
        æ™ºèƒ½æ¨¡å‹é€‰æ‹©
        
        Args:
            question: ç”¨æˆ·é—®é¢˜
            available_models: å¯ç”¨æ¨¡å‹åˆ—è¡¨
            
        Returns:
            é€‰æ‹©ç»“æœåŒ…å«æ¨èæ¨¡å‹å’Œåˆ†æç†ç”±
        """
        print("ğŸ§  æ­£åœ¨è¿›è¡Œæ™ºèƒ½æ¨¡å‹åˆ†æ...")
        
        # 1. æ„å»ºæ¨¡å‹çŸ¥è¯†æç¤º
        model_descriptions = self._build_model_descriptions(available_models)
        
        # 2. åˆ›å»ºåˆ†ææç¤º
        analysis_prompt = self._create_analysis_prompt(question, model_descriptions)
        
        # 3. LLMåˆ†æå’Œæ¨è
        try:
            response = await call_llm_async(
                messages=[{"role": "user", "content": analysis_prompt}],
                model=self.analyzer_model,
                max_tokens=1500,
                temperature=0.3
            )
            
            # 4. è§£ææ¨èç»“æœ
            recommendation = self._parse_recommendation(response, available_models)
            
            return recommendation
            
        except Exception as e:
            print(f"âš ï¸ æ™ºèƒ½é€‰æ‹©å¤±è´¥ï¼Œä½¿ç”¨å›é€€ç­–ç•¥: {str(e)}")
            return self._fallback_selection(question, available_models)
    
    def _build_model_descriptions(self, available_models: List[ModelConfig]) -> str:
        """æ„å»ºå¯ç”¨æ¨¡å‹çš„æè¿°"""
        descriptions = []
        
        for model in available_models:
            model_name = model.name
            if model_name in self.model_knowledge:
                capability = self.model_knowledge[model_name]
                
                desc = f"""
**{model_name}**:
- æ ¸å¿ƒä¼˜åŠ¿: {', '.join(capability.strengths)}
- é€‚åˆä»»åŠ¡: {', '.join(capability.suitable_tasks)}
- æ€§èƒ½ç‰¹ç‚¹: æ¨ç†èƒ½åŠ›{capability.performance_profile['reasoning']}, åˆ›é€ åŠ›{capability.performance_profile['creativity']}, ç¼–ç¨‹èƒ½åŠ›{capability.performance_profile['coding']}, äº‹å®å‡†ç¡®æ€§{capability.performance_profile['factual']}, å“åº”é€Ÿåº¦{capability.performance_profile['speed']}
- ç‰¹æ®ŠåŠŸèƒ½: {', '.join(capability.special_features)}
"""
                descriptions.append(desc)
            else:
                # å¯¹äºæœªçŸ¥æ¨¡å‹ï¼Œæä¾›åŸºæœ¬ä¿¡æ¯
                descriptions.append(f"**{model_name}**: é€šç”¨AIæ¨¡å‹ï¼Œå…·å¤‡åŸºç¡€çš„é—®ç­”å’Œåˆ†æèƒ½åŠ›")
        
        return "\n".join(descriptions)
    
    def _create_analysis_prompt(self, question: str, model_descriptions: str) -> str:
        """åˆ›å»ºåˆ†ææç¤º"""
        return f"""
ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„AIæ¨¡å‹é€‰æ‹©ä¸“å®¶ã€‚è¯·åˆ†æç”¨æˆ·é—®é¢˜å¹¶ä»å¯ç”¨æ¨¡å‹ä¸­æ¨èæœ€é€‚åˆçš„3ä¸ªæ¨¡å‹ç»„åˆã€‚

ç”¨æˆ·é—®é¢˜ï¼š
{question}

å¯ç”¨æ¨¡å‹åŠå…¶èƒ½åŠ›ï¼š
{model_descriptions}

è¯·æŒ‰ä»¥ä¸‹æ­¥éª¤è¿›è¡Œåˆ†æï¼š

1. **é—®é¢˜åˆ†æ**ï¼šåˆ†æé—®é¢˜çš„ç±»å‹ã€å¤æ‚åº¦ã€æ‰€éœ€èƒ½åŠ›
2. **éœ€æ±‚åŒ¹é…**ï¼šç¡®å®šè§£å†³è¿™ä¸ªé—®é¢˜éœ€è¦ä»€ä¹ˆæ ·çš„AIèƒ½åŠ›
3. **æ¨¡å‹è¯„ä¼°**ï¼šè¯„ä¼°æ¯ä¸ªæ¨¡å‹åœ¨è¿™ä¸ªé—®é¢˜ä¸Šçš„é€‚åˆåº¦
4. **ç»„åˆæ¨è**ï¼šé€‰æ‹©3ä¸ªæœ€é€‚åˆçš„æ¨¡å‹ï¼Œè€ƒè™‘èƒ½åŠ›äº’è¡¥

è¯·ä¸¥æ ¼æŒ‰ç…§ä»¥ä¸‹JSONæ ¼å¼è¾“å‡ºï¼š

```json
{{
    "problem_analysis": {{
        "question_type": "é—®é¢˜ç±»å‹",
        "complexity_level": "å¤æ‚åº¦ç­‰çº§(ç®€å•/ä¸­ç­‰/å¤æ‚)",
        "required_capabilities": ["æ‰€éœ€èƒ½åŠ›1", "æ‰€éœ€èƒ½åŠ›2", "æ‰€éœ€èƒ½åŠ›3"],
        "key_challenges": ["ä¸»è¦æŒ‘æˆ˜1", "ä¸»è¦æŒ‘æˆ˜2"]
    }},
    "recommended_models": [
        {{
            "model_name": "æ¨¡å‹åç§°",
            "rank": 1,
            "suitability_score": 9.5,
            "reasons": ["é€‰æ‹©ç†ç”±1", "é€‰æ‹©ç†ç”±2"],
            "expected_contribution": "é¢„æœŸè´¡çŒ®"
        }},
        {{
            "model_name": "æ¨¡å‹åç§°", 
            "rank": 2,
            "suitability_score": 8.8,
            "reasons": ["é€‰æ‹©ç†ç”±1", "é€‰æ‹©ç†ç”±2"],
            "expected_contribution": "é¢„æœŸè´¡çŒ®"
        }},
        {{
            "model_name": "æ¨¡å‹åç§°",
            "rank": 3, 
            "suitability_score": 8.2,
            "reasons": ["é€‰æ‹©ç†ç”±1", "é€‰æ‹©ç†ç”±2"],
            "expected_contribution": "é¢„æœŸè´¡çŒ®"
        }}
    ],
    "combination_strategy": "ç»„åˆç­–ç•¥è¯´æ˜",
    "confidence_level": "é«˜/ä¸­/ä½"
}}
```

æ³¨æ„ï¼š
- åªä»æä¾›çš„å¯ç”¨æ¨¡å‹ä¸­é€‰æ‹©
- ä¼˜å…ˆè€ƒè™‘èƒ½åŠ›äº’è¡¥çš„ç»„åˆ
- ç¡®ä¿æ¨èçš„æ¨¡å‹åç§°å®Œå…¨åŒ¹é…å¯ç”¨æ¨¡å‹åˆ—è¡¨
- é€‚åˆåº¦è¯„åˆ†èŒƒå›´ä¸º0-10åˆ†
"""
    
    def _parse_recommendation(
        self, 
        response: str, 
        available_models: List[ModelConfig]
    ) -> Dict[str, Any]:
        """è§£æLLMæ¨èç»“æœ"""
        
        try:
            # æå–JSONéƒ¨åˆ†
            json_match = re.search(r'```json\s*(.*?)\s*```', response, re.DOTALL)
            if json_match:
                json_str = json_match.group(1)
                recommendation = json.loads(json_str)
                
                # éªŒè¯æ¨èçš„æ¨¡å‹æ˜¯å¦åœ¨å¯ç”¨åˆ—è¡¨ä¸­
                available_model_names = [m.name for m in available_models]
                valid_models = []
                
                for rec_model in recommendation.get('recommended_models', []):
                    model_name = rec_model.get('model_name', '')
                    if model_name in available_model_names:
                        valid_models.append(rec_model)
                
                # å¦‚æœæœ‰æ•ˆæ¨¡å‹å°‘äº3ä¸ªï¼Œç”¨å›é€€ç­–ç•¥è¡¥å……
                if len(valid_models) < 3:
                    print(f"âš ï¸ æ™ºèƒ½æ¨èçš„æ¨¡å‹æ•°é‡ä¸è¶³({len(valid_models)})ï¼Œä½¿ç”¨å›é€€ç­–ç•¥è¡¥å……")
                    fallback = self._fallback_selection("", available_models)
                    
                    # è¡¥å……æ¨¡å‹
                    existing_names = [m['model_name'] for m in valid_models]
                    for model_name in fallback['selected_models'][:3]:
                        if model_name not in existing_names and len(valid_models) < 3:
                            valid_models.append({
                                'model_name': model_name,
                                'rank': len(valid_models) + 1,
                                'suitability_score': 7.0,
                                'reasons': ['å›é€€é€‰æ‹©'],
                                'expected_contribution': 'æä¾›å¤‡é€‰æ–¹æ¡ˆ'
                            })
                
                recommendation['recommended_models'] = valid_models[:3]
                recommendation['selected_models'] = [m['model_name'] for m in valid_models[:3]]
                recommendation['analysis_method'] = 'intelligent_llm'
                
                return recommendation
                
        except Exception as e:
            print(f"âš ï¸ è§£ææ¨èç»“æœå¤±è´¥: {str(e)}")
        
        # è§£æå¤±è´¥æ—¶ä½¿ç”¨å›é€€ç­–ç•¥
        return self._fallback_selection("", available_models)
    
    def _fallback_selection(
        self,
        question: str,
        available_models: List[ModelConfig]
    ) -> Dict[str, Any]:
        """å›é€€é€‰æ‹©ç­–ç•¥ - åŸºäºæ¨¡å‹èƒ½åŠ›çš„ä¼˜å…ˆçº§æ’åº"""

        # ä¼˜å…ˆçº§ç­–ç•¥ï¼šç»¼åˆèƒ½åŠ› > ä¸“ç²¾èƒ½åŠ› > è½»é‡æ¨¡å‹
        priority_order = [
            # é¡¶çº§ç»¼åˆèƒ½åŠ›æ¨¡å‹
            "claude_sonnet4", "qwen3-max-preview", "gpt-41-0414-global",
            # ä»£ç ä¸“ç²¾æ¨¡å‹
            "qwen3-coder-480b-a35b-instruct",
            # ä¼˜ç§€ç»¼åˆæ¨¡å‹
            "qwen-max", "openmatrix-qwen3-235b-inst-fp8",
            # å¹³è¡¡æ€§èƒ½æ¨¡å‹
            "claude37_sonnet_new", "qwen-plus", "qwen3-coder-plus1",
            # å¤šæ¨¡æ€å’Œåˆ›æ–°æ¨¡å‹
            "glm-4.5",
            # å¿«é€Ÿè½»é‡æ¨¡å‹
            "gpt-5-mini-0807-global", "gpt-41-mini-0414-global",
            "qwen3-coder-plus"
        ]
        
        available_names = [m.name for m in available_models]
        selected = []
        
        # æŒ‰ä¼˜å…ˆçº§é€‰æ‹©
        for model_name in priority_order:
            if model_name in available_names and len(selected) < 3:
                selected.append(model_name)
        
        # å¦‚æœä¸è¶³3ä¸ªï¼Œä»å‰©ä½™æ¨¡å‹ä¸­é€‰æ‹©
        while len(selected) < 3 and len(selected) < len(available_names):
            for model in available_models:
                if model.name not in selected:
                    selected.append(model.name)
                    break
        
        return {
            'problem_analysis': {
                'question_type': 'é€šç”¨é—®é¢˜',
                'complexity_level': 'ä¸­ç­‰',
                'required_capabilities': ['ç»¼åˆåˆ†æ', 'å‡†ç¡®å›ç­”'],
                'key_challenges': ['ä¿¡æ¯æ•´åˆ', 'é€»è¾‘æ¨ç†']
            },
            'recommended_models': [
                {
                    'model_name': model_name,
                    'rank': i + 1,
                    'suitability_score': 8.0 - i * 0.5,
                    'reasons': ['å›é€€ç­–ç•¥é€‰æ‹©'],
                    'expected_contribution': f'æä¾›{["ä¸»è¦", "è¾…åŠ©", "è¡¥å……"][i]}è§‚ç‚¹'
                }
                for i, model_name in enumerate(selected[:3])
            ],
            'selected_models': selected[:3],
            'combination_strategy': 'åŸºäºæ¨¡å‹ä¼˜å…ˆçº§çš„å›é€€é€‰æ‹©',
            'confidence_level': 'ä¸­',
            'analysis_method': 'fallback'
        }