"""
AI Fusion æŠ¥å‘Šç”Ÿæˆå™¨
ç”Ÿæˆè¯¦ç»†çš„markdownåˆ†ææŠ¥å‘Šï¼ŒåŒ…å«æ¨¡å‹æ€§èƒ½å¯¹æ¯”å’Œå›ç­”è´¨é‡åˆ†æ
"""

import os
from typing import List, Dict, Any, Optional
from datetime import datetime


class AIFusionReporter:
    """AI FusionæŠ¥å‘Šç”Ÿæˆå™¨"""
    
    def __init__(self):
        self.report_dir = "reports"
        self._ensure_report_dir()
    
    def _ensure_report_dir(self):
        """ç¡®ä¿æŠ¥å‘Šç›®å½•å­˜åœ¨"""
        if not os.path.exists(self.report_dir):
            os.makedirs(self.report_dir)
    
    def generate_report(
        self, 
        question: str, 
        question_type: str,
        llm_responses: List[Dict], 
        final_answer: str,
        selected_models: List[str],
        quality_analysis: Optional[Dict[str, Any]] = None,
        selection_analysis: Optional[Dict[str, Any]] = None
    ) -> str:
        """
        ç”Ÿæˆå®Œæ•´çš„markdownåˆ†ææŠ¥å‘Š
        
        Args:
            question: ç”¨æˆ·é—®é¢˜
            question_type: é—®é¢˜ç±»å‹
            llm_responses: å„æ¨¡å‹çš„å“åº”æ•°æ®
            final_answer: èåˆåçš„æœ€ç»ˆå›ç­”
            selected_models: é€‰æ‹©çš„æ¨¡å‹åˆ—è¡¨
            
        Returns:
            æŠ¥å‘Šæ–‡ä»¶è·¯å¾„
        """
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        filename = f"ai_fusion_report_{timestamp}.md"
        filepath = os.path.join(self.report_dir, filename)
        
        # ç”ŸæˆæŠ¥å‘Šå†…å®¹
        report_content = self._build_report_content(
            question, question_type, llm_responses, final_answer, selected_models, quality_analysis, selection_analysis
        )
        
        # å†™å…¥æ–‡ä»¶
        with open(filepath, 'w', encoding='utf-8') as f:
            f.write(report_content)
        
        print(f"ğŸ“Š åˆ†ææŠ¥å‘Šå·²ç”Ÿæˆ: {filepath}")
        return filepath
    
    def _build_report_content(
        self,
        question: str,
        question_type: str,
        llm_responses: List[Dict],
        final_answer: str,
        selected_models: List[str],
        quality_analysis: Optional[Dict[str, Any]] = None,
        selection_analysis: Optional[Dict[str, Any]] = None
    ) -> str:
        """æ„å»ºæŠ¥å‘Šå†…å®¹ - ä¼˜åŒ–ç‰ˆï¼Œä¸“æ³¨äºèåˆå›ç­”å’Œæœ€ä½³æ¨¡å‹è¡¨ç°"""

        # ç»Ÿè®¡ä¿¡æ¯
        total_models = len(llm_responses)
        fusion_length = len(final_answer)

        report = f"""# AI Fusion åˆ†ææŠ¥å‘Š

## ğŸ“‹ åŸºæœ¬ä¿¡æ¯
- **ç”Ÿæˆæ—¶é—´**: {datetime.now().strftime("%Y-%m-%d %H:%M:%S")}
- **é—®é¢˜ç±»å‹**: {question_type}
- **å‚ä¸æ¨¡å‹æ•°é‡**: {total_models}

## â“ ç”¨æˆ·é—®é¢˜
```
{question}
```

## ğŸ¯ AI Fusion èåˆå›ç­”
**å­—ç¬¦æ•°**: {fusion_length}

```
{final_answer}
```

## ğŸ† æœ€ä½³æ¨¡å‹è¡¨ç°

{self._generate_best_models_section(llm_responses, quality_analysis)}

---
*æœ¬æŠ¥å‘Šç”± AI Fusion ç³»ç»Ÿè‡ªåŠ¨ç”Ÿæˆ*
"""

        return report
    
    def _generate_best_models_section(self, llm_responses: List[Dict], quality_analysis: Optional[Dict[str, Any]]) -> str:
        """ç”Ÿæˆæœ€ä½³æ¨¡å‹è¡¨ç°éƒ¨åˆ† - æ˜¾ç¤ºæœ€å¿«å’Œæœ€é«˜è´¨é‡çš„æ¨¡å‹ï¼ŒåŒ…å«è¯¦ç»†çš„è¯„åˆ†è®¡ç®—è¯´æ˜"""
        section = ""

        # æ‰¾å‡ºå“åº”æ—¶é—´æœ€å¿«çš„æ¨¡å‹
        successful_responses = [r for r in llm_responses if r.get('success')]
        if successful_responses:
            fastest_model = min(successful_responses, key=lambda x: x.get('response_time', float('inf')))
            section += f"### ğŸš€ å“åº”é€Ÿåº¦æœ€å¿«\n\n"
            section += f"**{fastest_model['model_name']}**\n"
            section += f"- å“åº”æ—¶é—´: {fastest_model.get('response_time', 0):.2f}ç§’\n"
            section += f"- å›ç­”é•¿åº¦: {len(fastest_model['response'])}å­—ç¬¦\n\n"

        # æ‰¾å‡ºè´¨é‡æœ€é«˜çš„æ¨¡å‹å¹¶è¯¦ç»†è¯´æ˜è¯„åˆ†è®¡ç®—
        if quality_analysis and 'quality_ranking' in quality_analysis:
            ranking = quality_analysis['quality_ranking']
            # æ‰¾åˆ°è´¨é‡æœ€é«˜çš„éèåˆå›ç­”
            best_model_entry = next((item for item in ranking if not item['is_fusion']), None)

            if best_model_entry:
                section += f"### ğŸ† è´¨é‡è¯„åˆ†æœ€é«˜\n\n"
                section += f"**{best_model_entry['source']}**\n\n"

                # ç»¼åˆè¯„åˆ†
                section += f"#### ğŸ“Š ç»¼åˆè¯„åˆ†: {best_model_entry['overall_score']:.1f}/10\n\n"

                # è¯¦ç»†è¯„åˆ†åˆ†è§£
                section += f"#### ğŸ” è¯„åˆ†ç»†èŠ‚\n\n"

                # è·å–LLMè¯„ä¼°è¯¦æƒ…
                llm_evals = quality_analysis.get('llm_evaluations', {})
                model_eval = llm_evals.get(best_model_entry['source'])

                if model_eval:
                    # å®Œæ•´æ€§è¯„åˆ†
                    completeness = best_model_entry['completeness']
                    section += f"**1. å®Œæ•´æ€§è¯„åˆ†: {completeness:.1f}/10**\n"
                    section += f"- è¯„ä¼°æ ‡å‡†: å›ç­”æ˜¯å¦è¦†ç›–é—®é¢˜çš„æ‰€æœ‰å…³é”®æ–¹é¢\n"
                    if hasattr(model_eval, 'completeness_reasoning'):
                        section += f"- è¯„åˆ†ç†ç”±: {model_eval.completeness_reasoning}\n"
                    section += "\n"

                    # å‡†ç¡®æ€§è¯„åˆ†
                    accuracy = best_model_entry['accuracy']
                    section += f"**2. å‡†ç¡®æ€§è¯„åˆ†: {accuracy:.1f}/10**\n"
                    section += f"- è¯„ä¼°æ ‡å‡†: ä¿¡æ¯æ˜¯å¦å‡†ç¡®æ— è¯¯ï¼Œé€»è¾‘æ˜¯å¦ä¸¥å¯†\n"
                    if hasattr(model_eval, 'accuracy_reasoning'):
                        section += f"- è¯„åˆ†ç†ç”±: {model_eval.accuracy_reasoning}\n"
                    section += "\n"

                    # æ¸…æ™°åº¦è¯„åˆ†
                    clarity = best_model_entry['clarity']
                    section += f"**3. æ¸…æ™°åº¦è¯„åˆ†: {clarity:.1f}/10**\n"
                    section += f"- è¯„ä¼°æ ‡å‡†: è¡¨è¾¾æ˜¯å¦æ¸…æ™°æ˜“æ‡‚ï¼Œç»“æ„æ˜¯å¦åˆç†\n"
                    if hasattr(model_eval, 'clarity_reasoning'):
                        section += f"- è¯„åˆ†ç†ç”±: {model_eval.clarity_reasoning}\n"
                    section += "\n"

                    # ç›¸å…³æ€§è¯„åˆ†
                    relevance = best_model_entry['relevance']
                    section += f"**4. ç›¸å…³æ€§è¯„åˆ†: {relevance:.1f}/10**\n"
                    section += f"- è¯„ä¼°æ ‡å‡†: å†…å®¹æ˜¯å¦åˆ‡é¢˜ï¼Œæ˜¯å¦ç›´æ¥å›ç­”äº†é—®é¢˜\n"
                    if hasattr(model_eval, 'relevance_reasoning'):
                        section += f"- è¯„åˆ†ç†ç”±: {model_eval.relevance_reasoning}\n"
                    section += "\n"

                    # ç»¼åˆè¯„åˆ†è®¡ç®—è¯´æ˜
                    section += f"**ç»¼åˆè¯„åˆ†è®¡ç®—æ–¹å¼:**\n"
                    section += f"```\n"
                    section += f"ç»¼åˆè¯„åˆ† = (å®Œæ•´æ€§ + å‡†ç¡®æ€§ + æ¸…æ™°åº¦ + ç›¸å…³æ€§) / 4\n"
                    section += f"         = ({completeness:.1f} + {accuracy:.1f} + {clarity:.1f} + {relevance:.1f}) / 4\n"
                    section += f"         = {best_model_entry['overall_score']:.1f}/10\n"
                    section += f"```\n\n"

                    # æ€»ä½“è¯„ä»·
                    if hasattr(model_eval, 'overall_assessment'):
                        section += f"**ğŸ’­ æ€»ä½“è¯„ä»·:**\n{model_eval.overall_assessment}\n\n"
                else:
                    # å¦‚æœæ²¡æœ‰è¯¦ç»†è¯„ä¼°æ•°æ®ï¼Œæ˜¾ç¤ºåŸºæœ¬ä¿¡æ¯
                    section += f"- å®Œæ•´æ€§: {best_model_entry['completeness']:.1f}/10\n"
                    section += f"- å‡†ç¡®æ€§: {best_model_entry['accuracy']:.1f}/10\n"
                    section += f"- æ¸…æ™°åº¦: {best_model_entry['clarity']:.1f}/10\n"
                    section += f"- ç›¸å…³æ€§: {best_model_entry['relevance']:.1f}/10\n\n"
                    section += f"**ç»¼åˆè¯„åˆ†** = (å®Œæ•´æ€§ + å‡†ç¡®æ€§ + æ¸…æ™°åº¦ + ç›¸å…³æ€§) / 4 = {best_model_entry['overall_score']:.1f}/10\n\n"
        else:
            section += f"### ğŸ† è´¨é‡è¯„åˆ†æœ€é«˜\n\n"
            section += f"_è´¨é‡åˆ†ææ•°æ®ä¸å¯ç”¨_\n\n"

        return section

    def _generate_quality_analysis_section(self, quality_analysis: Optional[Dict[str, Any]]) -> str:
        """ç”Ÿæˆè´¨é‡åˆ†æéƒ¨åˆ†"""
        if not quality_analysis:
            return "è´¨é‡åˆ†æåŠŸèƒ½æœªå¯ç”¨ã€‚"
        
        section = ""
        
        # è´¨é‡æ’å
        if 'quality_ranking' in quality_analysis:
            section += "### ğŸ“Š è´¨é‡è¯„åˆ†æ’å\n\n"
            section += "| æ’å | æ¥æº | ç»¼åˆè¯„åˆ† | å®Œæ•´æ€§ | å‡†ç¡®æ€§ | æ¸…æ™°åº¦ | ç›¸å…³æ€§ | å­—æ•° |\n"
            section += "|------|------|----------|--------|--------|--------|--------|------|\n"
            
            for item in quality_analysis['quality_ranking']:
                source_display = "ğŸ¯ èåˆå›ç­”" if item['is_fusion'] else f"ğŸ¤– {item['source']}"
                section += f"| {item['rank']} | {source_display} | {item['overall_score']:.1f} | {item['completeness']:.1f} | {item['accuracy']:.1f} | {item['clarity']:.1f} | {item['relevance']:.1f} | {item['word_count']} |\n"
            
            section += "\n"
        
        # å¯¹æ¯”åˆ†æ
        if 'comparison_analysis' in quality_analysis:
            comp_analysis = quality_analysis['comparison_analysis']
            
            # èåˆä¼˜åŠ¿
            if comp_analysis.get('fusion_advantages'):
                section += "### ğŸš€ èåˆå›ç­”ä¼˜åŠ¿\n\n"
                for advantage in comp_analysis['fusion_advantages']:
                    section += f"- âœ… {advantage}\n"
                section += "\n"
            
            # å„æ¨¡å‹å¼ºé¡¹ - ä¸ªæ€§åŒ–åˆ†æ
            if comp_analysis.get('model_strengths'):
                section += "### ğŸ’ª å„æ¨¡å‹åœ¨æœ¬æ¬¡ä»»åŠ¡ä¸­çš„ä¼˜åŠ¿è¡¨ç°\n\n"
                for model, strengths in comp_analysis['model_strengths'].items():
                    section += f"**{model}**: {', '.join(strengths)}\n"
                section += "\n"
            
            # **æ–°å¢ï¼šæ·±åº¦ä¸ªæ€§åŒ–æ¡£æ¡ˆ**
            content_analysis = quality_analysis.get('content_analysis', {})
            individualized_profiles = content_analysis.get('individualized_profiles', {})
            if individualized_profiles and isinstance(individualized_profiles, dict):
                profiles_data = individualized_profiles.get('individualized_profiles', {})
                if profiles_data:
                    section += "### ğŸ¯ æ·±åº¦ä¸ªæ€§åŒ–æ¡£æ¡ˆ\n\n"
                    section += "> åŸºäºå†…å®¹æ·±åº¦åˆ†æï¼Œä¸ºæ¯ä¸ªæ¨¡å‹ç”Ÿæˆçš„ç‹¬ç‰¹ç‰¹å¾æ¡£æ¡ˆ\n\n"

                    for model_name, profile in profiles_data.items():
                        section += f"#### {model_name}\n\n"

                        # æ ‡å¿—æ€§ç‰¹å¾
                        signature = profile.get('signature_characteristics', '')
                        if signature:
                            section += f"**ğŸ·ï¸ æ ‡å¿—æ€§ç‰¹å¾**: {signature}\n\n"

                        # å†…å®¹é£æ ¼
                        style = profile.get('content_style', '')
                        if style:
                            section += f"**ğŸ“ å†…å®¹é£æ ¼**: {style}\n\n"

                        # è§£ç­”è§’åº¦ä¸æ·±åº¦
                        approach = profile.get('approach_depth', '')
                        if approach:
                            section += f"**ğŸ¯ è§£ç­”è§’åº¦**: {approach}\n\n"

                        # ç‹¬ç‰¹è´¡çŒ®ç‚¹
                        contributions = profile.get('unique_contributions', [])
                        if contributions:
                            section += f"**ğŸ’¡ ç‹¬ç‰¹è´¡çŒ®**:\n"
                            for contrib in contributions:
                                section += f"- {contrib}\n"
                            section += "\n"

                        # æ¯”è¾ƒä¼˜åŠ¿ä¸ä¸è¶³
                        advantage = profile.get('comparative_advantage', '')
                        weakness = profile.get('comparative_weakness', '')
                        if advantage or weakness:
                            section += f"**âš–ï¸ å¯¹æ¯”åˆ†æ**:\n"
                            if advantage:
                                section += f"- âœ… **ä¼˜åŠ¿**: {advantage}\n"
                            if weakness:
                                section += f"- âš ï¸ **ä¸è¶³**: {weakness}\n"
                            section += "\n"

                        # é€‚ç”¨åœºæ™¯
                        scenarios = profile.get('best_use_scenarios', [])
                        if scenarios:
                            section += f"**ğŸ¬ æœ€ä½³é€‚ç”¨åœºæ™¯**:\n"
                            for scenario in scenarios:
                                section += f"- {scenario}\n"
                            section += "\n"

                        section += "---\n\n"

                    # å·®å¼‚åŒ–æ€»ç»“
                    diff_summary = individualized_profiles.get('differentiation_summary', '')
                    if diff_summary:
                        section += f"**ğŸ” å·®å¼‚åŒ–æ€»ç»“**: {diff_summary}\n\n"

            # # è¯¦ç»†ä¸ªä½“åˆ†æï¼ˆä½œä¸ºè¡¥å……ï¼‰
            # if comp_analysis.get('individual_analysis'):
            #     section += "### ğŸ“Š å„æ¨¡å‹è¯¦ç»†è¡¨ç°åˆ†æ\n\n"
            #     for model, analysis in comp_analysis['individual_analysis'].items():
            #         section += f"#### {model}\n\n"
            #
            #         highlights = analysis.get('performance_highlights', [])
            #         if highlights:
            #             section += f"- **æ€§èƒ½äº®ç‚¹**: {', '.join(highlights)}\n"
            #
            #         ranking = analysis.get('relative_ranking', {})
            #         if ranking:
            #             section += f"- **æœ¬æ¬¡æ’å**: å®Œæ•´æ€§{ranking.get('completeness', 'N/A')}, å‡†ç¡®æ€§{ranking.get('accuracy', 'N/A')}, æ¸…æ™°åº¦{ranking.get('clarity', 'N/A')}, ç›¸å…³æ€§{ranking.get('relevance', 'N/A')}\n"
            #
            #         style = analysis.get('style_characteristics', [])
            #         if style:
            #             section += f"- **å›ç­”é£æ ¼**: {', '.join(style)}\n"
            #
            #         potential = analysis.get('improvement_potential', [])
            #         if potential:
            #             section += f"- **åˆ†æå»ºè®®**: {', '.join(potential)}\n"
            #
            #         section += "\n"
            
            # ç»Ÿè®¡æ‘˜è¦
            if comp_analysis.get('statistical_summary'):
                stats = comp_analysis['statistical_summary']
                section += "### ğŸ“ˆ è´¨é‡ç»Ÿè®¡æ‘˜è¦\n\n"
                section += f"- **èåˆå›ç­”è¯„åˆ†**: {stats.get('fusion_overall_score', 0):.1f}/10\n"
                section += f"- **æ¨¡å‹å¹³å‡è¯„åˆ†**: {stats.get('models_avg_score', 0):.1f}/10\n"
                section += f"- **è´¨é‡æå‡**: {stats.get('improvement', 0):+.1f}åˆ†\n"
                section += f"- **æœ€ä½³å•æ¨¡å‹è¯„åˆ†**: {stats.get('best_individual_score', 0):.1f}/10\n"
                section += f"- **vsæœ€ä½³å•æ¨¡å‹**: {stats.get('fusion_vs_best', 0):+.1f}åˆ†\n\n"
        
        return section
    
    def _generate_quality_summary(self, quality_analysis: Optional[Dict[str, Any]]) -> str:
        """ç”Ÿæˆè´¨é‡æ‘˜è¦"""
        if not quality_analysis:
            return ""
        
        summary = "\n### ğŸ¯ è´¨é‡åˆ†ææ€»ç»“\n\n"
        
        if 'comparison_analysis' in quality_analysis:
            stats = quality_analysis['comparison_analysis'].get('statistical_summary', {})
            improvement = stats.get('improvement', 0)
            
            if improvement > 0:
                summary += f"- **è´¨é‡æå‡**: èåˆå›ç­”æ¯”å•æ¨¡å‹å¹³å‡è´¨é‡æå‡äº† {improvement:.1f} åˆ†\n"
            elif improvement < 0:
                summary += f"- **è´¨é‡å¯¹æ¯”**: èåˆå›ç­”æ¯”å•æ¨¡å‹å¹³å‡è´¨é‡ä½ {abs(improvement):.1f} åˆ†\n"
            else:
                summary += f"- **è´¨é‡å¯¹æ¯”**: èåˆå›ç­”ä¸å•æ¨¡å‹å¹³å‡è´¨é‡æŒå¹³\n"
            
            fusion_vs_best = stats.get('fusion_vs_best', 0)
            if fusion_vs_best > 0:
                summary += f"- **æœ€ä½³å¯¹æ¯”**: èåˆå›ç­”è¶…è¶Šäº†æœ€ä½³å•æ¨¡å‹ {fusion_vs_best:.1f} åˆ†\n"
            elif fusion_vs_best < 0:
                summary += f"- **æœ€ä½³å¯¹æ¯”**: èåˆå›ç­”æ¯”æœ€ä½³å•æ¨¡å‹ä½ {abs(fusion_vs_best):.1f} åˆ†\n"
            else:
                summary += f"- **æœ€ä½³å¯¹æ¯”**: èåˆå›ç­”ä¸æœ€ä½³å•æ¨¡å‹è´¨é‡ç›¸å½“\n"
        
        return summary
    
    def _generate_intelligent_recommendations(
        self, 
        question_type: str,
        llm_responses: List[Dict],
        final_answer: str,
        quality_analysis: Optional[Dict[str, Any]] = None,
        selection_analysis: Optional[Dict[str, Any]] = None
    ) -> str:
        """ç”Ÿæˆæ™ºèƒ½å»ºè®®å’Œæ€»ç»“"""
        
        recommendations = []
        
        # æ€§èƒ½åˆ†æå»ºè®®
        if llm_responses:
            # æ‰¾å‡ºæœ€å¿«å’Œæœ€æ…¢çš„æ¨¡å‹
            response_times = [(r['model_name'], r.get('response_time', 0)) for r in llm_responses if r.get('success')]
            if response_times:
                fastest = min(response_times, key=lambda x: x[1])
                slowest = max(response_times, key=lambda x: x[1])
                
                recommendations.append(f"### âš¡ æ€§èƒ½è¡¨ç°")
                recommendations.append(f"- **å“åº”é€Ÿåº¦å† å†›**: {fastest[0]} ({fastest[1]:.2f}ç§’)")
                
                if slowest[1] - fastest[1] > 2:
                    recommendations.append(f"- **ä¼˜åŒ–å»ºè®®**: {slowest[0]} å“åº”è¾ƒæ…¢({slowest[1]:.2f}ç§’)ï¼Œåœ¨æ—¶é—´æ•æ„Ÿåœºæ™¯ä¸‹å¯ä¼˜å…ˆé€‰æ‹©æ›´å¿«çš„æ¨¡å‹")
                
                avg_time = sum(t for _, t in response_times) / len(response_times)
                recommendations.append(f"- **å¹³å‡å“åº”æ—¶é—´**: {avg_time:.2f}ç§’")
        
        # æ¨¡å‹é€‰æ‹©å»ºè®®
        if selection_analysis:
            analysis_method = selection_analysis.get('analysis_method', '')
            confidence = selection_analysis.get('confidence_level', '')
            
            recommendations.append(f"\n### ğŸ¯ æ¨¡å‹é€‰æ‹©æ•ˆæœ")
            
            if analysis_method == 'intelligent_llm':
                recommendations.append(f"- **é€‰æ‹©æ–¹å¼**: ğŸ§  æ™ºèƒ½LLMåˆ†æï¼Œç½®ä¿¡åº¦: {confidence}")
                recommendations.append(f"- **é—®é¢˜é€‚é…**: å½“å‰æ¨¡å‹ç»„åˆç»è¿‡AIæ·±åº¦åˆ†æï¼Œé’ˆå¯¹\"{question_type}\"ç±»å‹é—®é¢˜è¿›è¡Œäº†ä¼˜åŒ–é€‰æ‹©")
            elif analysis_method == 'fallback':
                recommendations.append(f"- **é€‰æ‹©æ–¹å¼**: ğŸ”„ ä¼ ç»Ÿè§„åˆ™åŒ¹é…ï¼Œå»ºè®®æ£€æŸ¥æ™ºèƒ½é€‰æ‹©å™¨çŠ¶æ€")
                recommendations.append(f"- **æ”¹è¿›å»ºè®®**: æ™ºèƒ½é€‰æ‹©åŠŸèƒ½å¼‚å¸¸ï¼Œå»ºè®®æ’æŸ¥ç½‘ç»œæˆ–APIçŠ¶æ€")
            
            problem_analysis = selection_analysis.get('problem_analysis', {})
            if problem_analysis:
                complexity = problem_analysis.get('complexity_level', '')
                if complexity == 'å¤æ‚':
                    recommendations.append(f"- **å¤æ‚åº¦è¯„ä¼°**: é«˜å¤æ‚åº¦é—®é¢˜ï¼Œå¤šæ¨¡å‹èåˆç­–ç•¥å¾—å½“")
                elif complexity == 'ç®€å•':
                    recommendations.append(f"- **æ•ˆç‡ä¼˜åŒ–**: ç®€å•é—®é¢˜å¯è€ƒè™‘ä½¿ç”¨æ›´å¿«çš„è½»é‡çº§æ¨¡å‹ç»„åˆ")
        
        # è´¨é‡åˆ†æå»ºè®®
        if quality_analysis:
            ranking = quality_analysis.get('quality_ranking', [])
            if ranking:
                best_model = ranking[0] if ranking else None
                fusion_rank = next((i+1 for i, r in enumerate(ranking) if r['is_fusion']), None)
                
                recommendations.append(f"\n### ğŸ“Š è´¨é‡è¡¨ç°æ´å¯Ÿ")
                
                if fusion_rank == 1:
                    recommendations.append(f"- **èåˆæ•ˆæœ**: ğŸ† èåˆå›ç­”è·å¾—æœ€é«˜è´¨é‡è¯„åˆ†ï¼Œå¤šæ¨¡å‹åä½œæ•ˆæœæ˜¾è‘—")
                elif fusion_rank == 2:
                    recommendations.append(f"- **èåˆæ•ˆæœ**: ğŸ¥ˆ èåˆå›ç­”è´¨é‡ä¼˜ç§€ï¼Œç•¥é€Šäºæœ€ä½³å•æ¨¡å‹ä½†æ•´ä½“è¡¨ç°ç¨³å®š")
                elif fusion_rank and fusion_rank <= 3:
                    recommendations.append(f"- **èåˆæ•ˆæœ**: ğŸ¥‰ èåˆå›ç­”è¿›å…¥å‰ä¸‰ï¼Œåœ¨æŸäº›ç»´åº¦ä¸Šæœ‰æ‰€æå‡")
                else:
                    recommendations.append(f"- **èåˆæ•ˆæœ**: âš ï¸ èåˆå›ç­”æœªè¾¾åˆ°é¢„æœŸï¼Œå»ºè®®æ£€æŸ¥æ¨¡å‹é€‰æ‹©ç­–ç•¥")
                
                if best_model and not best_model['is_fusion']:
                    recommendations.append(f"- **å•æ¨¡å‹ä¼˜ç§€**: {best_model['source']} åœ¨æœ¬æ¬¡ä»»åŠ¡ä¸­è¡¨ç°æœ€ä½³(è¯„åˆ†: {best_model['overall_score']:.1f})")
            
            # åˆ†æå„æ¨¡å‹ä¼˜åŠ¿
            comp_analysis = quality_analysis.get('comparison_analysis', {})
            model_strengths = comp_analysis.get('model_strengths', {})
            
            if model_strengths:
                recommendations.append(f"\n### ğŸ” æ¨¡å‹ç‰¹é•¿å‘ç°")
                for model, strengths in model_strengths.items():
                    if strengths:
                        primary_strength = strengths[0]  # å–ä¸»è¦ä¼˜åŠ¿
                        recommendations.append(f"- **{model}**: {primary_strength}ï¼Œå»ºè®®åœ¨ç›¸å…³åœºæ™¯ä¸­ä¼˜å…ˆè€ƒè™‘")
        
        # åŸºäºé—®é¢˜ç±»å‹çš„ä¸“ä¸šå»ºè®®
        recommendations.append(f"\n### ğŸ’­ é’ˆå¯¹\"{question_type}\"é—®é¢˜çš„ä¸“ä¸šå»ºè®®")
        
        type_recommendations = {
            'æŠ€æœ¯/ç¼–ç¨‹': [
                "å¯¹äºç¼–ç¨‹é—®é¢˜ï¼Œå»ºè®®ä¼˜å…ˆé€‰æ‹©é€»è¾‘æ¨ç†èƒ½åŠ›å¼ºçš„æ¨¡å‹",
                "å¯è€ƒè™‘è®©ä¸åŒæ¨¡å‹åˆ†åˆ«å¤„ç†ç®—æ³•è®¾è®¡ã€ä»£ç å®ç°å’Œä¼˜åŒ–å»ºè®®",
                "èåˆæ—¶æ³¨æ„ä»£ç çš„å¯æ‰§è¡Œæ€§å’Œæœ€ä½³å®è·µ"
            ],
            'åˆ›æ„å†™ä½œ': [
                "åˆ›æ„ç±»é—®é¢˜é€‚åˆå‘æŒ¥å„æ¨¡å‹çš„æƒ³è±¡åŠ›å·®å¼‚",
                "å»ºè®®èåˆæ—¶ä¿æŒåˆ›æ„çš„å¤šæ ·æ€§å’ŒåŸåˆ›æ€§",
                "å¯è®©ä¸åŒæ¨¡å‹æä¾›ä¸åŒçš„åˆ›ä½œè§’åº¦å’Œé£æ ¼"
            ],
            'æ•°å­¦/é€»è¾‘': [
                "æ•°å­¦é—®é¢˜éœ€è¦ç¡®ä¿è®¡ç®—çš„å‡†ç¡®æ€§",
                "å»ºè®®è®©å¤šä¸ªæ¨¡å‹éªŒè¯è®¡ç®—è¿‡ç¨‹å’Œç»“æœ",
                "èåˆæ—¶åº”ä¼˜å…ˆè€ƒè™‘é€»è¾‘ä¸¥è°¨æ€§"
            ],
            'æ—¥å¸¸å¯¹è¯': [
                "æ—¥å¸¸å¯¹è¯æ³¨é‡è‡ªç„¶æ€§å’Œå®ç”¨æ€§",
                "å¯é€‚å½“ç®€åŒ–æ¨¡å‹é…ç½®ä»¥æé«˜å“åº”é€Ÿåº¦",
                "èåˆæ—¶ä¿æŒå›ç­”çš„äº²å’ŒåŠ›å’Œæ˜“æ‡‚æ€§"
            ],
            'ä¸“ä¸šçŸ¥è¯†': [
                "ä¸“ä¸šé—®é¢˜éœ€è¦ç¡®ä¿çŸ¥è¯†çš„æƒå¨æ€§å’Œå‡†ç¡®æ€§",
                "å»ºè®®é€‰æ‹©çŸ¥è¯†ä¸°å¯Œä¸”åœ¨è¯¥é¢†åŸŸæœ‰ä¼˜åŠ¿çš„æ¨¡å‹",
                "èåˆæ—¶æ³¨æ„ä¸“ä¸šæœ¯è¯­çš„å‡†ç¡®ä½¿ç”¨"
            ],
            'ç¿»è¯‘': [
                "ç¿»è¯‘ä»»åŠ¡éœ€è¦å¹³è¡¡å‡†ç¡®æ€§å’Œæµç•…æ€§",
                "å»ºè®®é€‰æ‹©å¤šè¯­è¨€èƒ½åŠ›å¼ºçš„æ¨¡å‹ç»„åˆ",
                "èåˆæ—¶æ³¨æ„ä¿æŒåŸæ–‡æ„å¢ƒå’Œç›®æ ‡è¯­è¨€ä¹ æƒ¯"
            ],
            'åˆ†ææ€»ç»“': [
                "åˆ†æç±»é—®é¢˜éœ€è¦é€»è¾‘æ¸…æ™°å’Œç»“æ„å®Œæ•´",
                "å»ºè®®è®©ä¸åŒæ¨¡å‹ä»ä¸åŒè§’åº¦è¿›è¡Œåˆ†æ",
                "èåˆæ—¶ç¡®ä¿ç»“è®ºçš„é€»è¾‘æ€§å’Œè¯´æœåŠ›"
            ]
        }
        
        specific_recs = type_recommendations.get(question_type, [
            "æ ¹æ®é—®é¢˜ç‰¹ç‚¹é€‰æ‹©åˆé€‚çš„æ¨¡å‹ç»„åˆ",
            "æ³¨æ„å‘æŒ¥å„æ¨¡å‹çš„äº’è¡¥ä¼˜åŠ¿",
            "èåˆæ—¶ç¡®ä¿å›ç­”çš„å‡†ç¡®æ€§å’Œå®Œæ•´æ€§"
        ])
        
        for rec in specific_recs:
            recommendations.append(f"- {rec}")
        
        # æœªæ¥ä¼˜åŒ–å»ºè®®
        recommendations.append(f"\n### ğŸš€ æœªæ¥ä¼˜åŒ–æ–¹å‘")
        
        if quality_analysis and selection_analysis:
            # åŸºäºæœ¬æ¬¡è¡¨ç°ç»™å‡ºå…·ä½“å»ºè®®
            stats = quality_analysis.get('comparison_analysis', {}).get('statistical_summary', {})
            improvement = stats.get('improvement', 0)
            
            if improvement > 1:
                recommendations.append(f"- **ç»§ç»­ä¼˜åŒ–**: å½“å‰èåˆæ•ˆæœä¼˜ç§€ï¼Œå¯å°è¯•æ›´å¤šæ ·åŒ–çš„é—®é¢˜ç±»å‹")
            elif improvement > 0:
                recommendations.append(f"- **å¾®è°ƒä¼˜åŒ–**: èåˆæœ‰æ•ˆæœä½†æå‡æœ‰é™ï¼Œå¯è€ƒè™‘è°ƒæ•´æ¨¡å‹æƒé‡æˆ–é€‰æ‹©ç­–ç•¥")
            else:
                recommendations.append(f"- **ç­–ç•¥è°ƒæ•´**: èåˆæ•ˆæœä¸ç†æƒ³ï¼Œå»ºè®®é‡æ–°è¯„ä¼°æ¨¡å‹é€‰æ‹©æ ‡å‡†")
            
            recommendations.append(f"- **æ•°æ®ç§¯ç´¯**: æŒç»­æ”¶é›†å„ç±»é—®é¢˜çš„æ¨¡å‹è¡¨ç°æ•°æ®ï¼Œä¼˜åŒ–é€‰æ‹©ç®—æ³•")
            recommendations.append(f"- **ä¸ªæ€§å®šåˆ¶**: æ ¹æ®ç”¨æˆ·åå¥½å’Œä½¿ç”¨åœºæ™¯å®šåˆ¶ä¸“å±çš„æ¨¡å‹ç»„åˆæ–¹æ¡ˆ")
        
        return "\n".join(recommendations)
    
    def _generate_selection_analysis_section(self, selection_analysis: Optional[Dict[str, Any]]) -> str:
        """ç”Ÿæˆæ™ºèƒ½é€‰æ‹©åˆ†æéƒ¨åˆ†"""
        if not selection_analysis:
            return "æ™ºèƒ½é€‰æ‹©åˆ†æåŠŸèƒ½æœªå¯ç”¨ã€‚"
        
        section = ""
        
        # é—®é¢˜åˆ†æ
        problem_analysis = selection_analysis.get('problem_analysis', {})
        if problem_analysis:
            section += "### ğŸ“‹ é—®é¢˜æ·±åº¦åˆ†æ\n\n"
            section += f"- **é—®é¢˜ç±»å‹**: {problem_analysis.get('question_type', 'æœªçŸ¥')}\n"
            section += f"- **å¤æ‚åº¦ç­‰çº§**: {problem_analysis.get('complexity_level', 'æœªçŸ¥')}\n"
            
            capabilities = problem_analysis.get('required_capabilities', [])
            if capabilities:
                section += f"- **æ‰€éœ€èƒ½åŠ›**: {', '.join(capabilities)}\n"
            
            challenges = problem_analysis.get('key_challenges', [])
            if challenges:
                section += f"- **ä¸»è¦æŒ‘æˆ˜**: {', '.join(challenges)}\n"
            
            section += "\n"
        
        # æ¨¡å‹æ¨èè¯¦æƒ…
        recommended_models = selection_analysis.get('recommended_models', [])
        if recommended_models:
            section += "### ğŸ¯ æ™ºèƒ½æ¨èè¯¦æƒ…\n\n"
            section += "| æ’å | æ¨¡å‹åç§° | é€‚åˆåº¦è¯„åˆ† | é€‰æ‹©ç†ç”± | é¢„æœŸè´¡çŒ® |\n"
            section += "|------|----------|------------|----------|----------|\n"
            
            for model in recommended_models:
                rank = model.get('rank', 0)
                name = model.get('model_name', '')
                score = model.get('suitability_score', 0)
                reasons = '; '.join(model.get('reasons', []))
                contribution = model.get('expected_contribution', '')
                
                section += f"| {rank} | {name} | {score}/10 | {reasons} | {contribution} |\n"
            
            section += "\n"
        
        # ç»„åˆç­–ç•¥
        strategy = selection_analysis.get('combination_strategy', '')
        confidence = selection_analysis.get('confidence_level', '')
        analysis_method = selection_analysis.get('analysis_method', '')
        
        if strategy or confidence or analysis_method:
            section += "### ğŸ”— é€‰æ‹©ç­–ç•¥ä¸ç½®ä¿¡åº¦\n\n"
            
            if strategy:
                section += f"- **ç»„åˆç­–ç•¥**: {strategy}\n"
            if confidence:
                section += f"- **ç½®ä¿¡åº¦**: {confidence}\n"
            if analysis_method:
                method_display = {
                    'intelligent_llm': 'ğŸ§  LLMæ™ºèƒ½åˆ†æ',
                    'fallback': 'ğŸ”„ ä¼ ç»Ÿè§„åˆ™åŒ¹é…',
                    'unknown': 'â“ æœªçŸ¥æ–¹æ³•'
                }.get(analysis_method, analysis_method)
                section += f"- **åˆ†ææ–¹æ³•**: {method_display}\n"
            
            section += "\n"
        
        return section
    
    def print_summary(self, llm_responses: List[Dict], final_answer: str, quality_analysis: Optional[Dict[str, Any]] = None):
        """æ‰“å°ç®€è¦æ‘˜è¦"""
        print("\n" + "="*60)
        print("ğŸ“Š AI Fusion åˆ†ææ‘˜è¦")
        print("="*60)
        
        for i, response in enumerate(llm_responses, 1):
            if response['success']:
                print(f"ğŸ¤– æ¨¡å‹ {i}: {response['model_name']}")
                print(f"   â±ï¸  å“åº”æ—¶é—´: {response.get('response_time', 0):.2f}ç§’")
                print(f"   ğŸ“ å›ç­”é•¿åº¦: {len(response['response'])}å­—ç¬¦")
                print(f"   âœ… çŠ¶æ€: æˆåŠŸ")
            else:
                print(f"âŒ æ¨¡å‹ {i}: {response['model_name']} - å¤±è´¥")
                print(f"   â±ï¸  å“åº”æ—¶é—´: {response.get('response_time', 0):.2f}ç§’")
                print(f"   ğŸ“ é”™è¯¯: {response.get('error', 'Unknown')}")
            print()
        
        print(f"ğŸ¯ èåˆå›ç­”é•¿åº¦: {len(final_answer)}å­—ç¬¦")
        print("="*60)